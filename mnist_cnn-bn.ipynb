{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST CNN (without BN vs with BN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 950 (CNMeM is enabled with initial size: 90.0% of memory, cuDNN 5110)\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox import cuda\n",
    "cuda.use('gpu0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_test = np.expand_dims(X_test,1)\n",
    "X_train = np.expand_dims(X_train,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_train = onehot(y_train)\n",
    "y_test = onehot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_input(x): return (x-mean_px)/std_px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Conv model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_conv_model(lr=0.001):\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1,28,28)),\n",
    "        ZeroPadding2D((1, 1)),\n",
    "        Convolution2D(32, 3, 3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        ZeroPadding2D((1, 1)),\n",
    "        Convolution2D(64, 3, 3, activation='relu'),  \n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(lr=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning rate 0.001 -> 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsuyoshi/.pyenv/versions/anaconda3-4.3.0/envs/py2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_12 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "conv_model = get_conv_model(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_12 (Lambda)               (None, 1, 28, 28)     0           lambda_input_12[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_23 (ZeroPadding2D) (None, 1, 30, 30)     0           lambda_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_23 (Convolution2D) (None, 32, 28, 28)    320         zeropadding2d_23[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_23 (MaxPooling2D)   (None, 32, 14, 14)    0           convolution2d_23[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_24 (ZeroPadding2D) (None, 32, 16, 16)    0           maxpooling2d_23[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_24 (Convolution2D) (None, 64, 14, 14)    18496       zeropadding2d_24[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_24 (MaxPooling2D)   (None, 64, 7, 7)      0           convolution2d_24[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)             (None, 3136)          0           maxpooling2d_24[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_23 (Dense)                 (None, 512)           1606144     flatten_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 512)           0           dense_23[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_24 (Dense)                 (None, 10)            5130        dropout_12[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1,630,090\n",
      "Trainable params: 1,630,090\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator()\n",
    "batches = gen.flow(X_train, y_train, batch_size=64) # keras.preprocessing.image.NumpyArrayIterator\n",
    "test_batches = gen.flow(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 15s - loss: 0.1371 - acc: 0.9567 - val_loss: 0.0374 - val_acc: 0.9870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4f2ae6afd0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model.fit_generator(batches, batches.n, nb_epoch=1, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why is loss much higher than val_loss ?\n",
    "\n",
    "https://faroit.github.io/keras-docs/1.2.2/getting-started/faq/#why-is-the-training-loss-much-higher-than-the-testing-loss\n",
    "\n",
    "> Besides, the training loss is the average of the losses over each batch of training data. Because your model is changing over time, the loss over the first batches of an epoch is generally higher than over the last batches. On the other hand, the testing loss for an epoch is computed using the model as it is at the end of the epoch, resulting in a lower loss.\n",
    "\n",
    "Also, in evaluation, we don't use dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 15s - loss: 0.0506 - acc: 0.9846 - val_loss: 0.0348 - val_acc: 0.9877\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 14s - loss: 0.0335 - acc: 0.9895 - val_loss: 0.0262 - val_acc: 0.9912\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 15s - loss: 0.0279 - acc: 0.9910 - val_loss: 0.0272 - val_acc: 0.9913\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 15s - loss: 0.0224 - acc: 0.9928 - val_loss: 0.0227 - val_acc: 0.9931\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 14s - loss: 0.0187 - acc: 0.9938 - val_loss: 0.0280 - val_acc: 0.9911\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 14s - loss: 0.0160 - acc: 0.9950 - val_loss: 0.0213 - val_acc: 0.9940\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 15s - loss: 0.0133 - acc: 0.9956 - val_loss: 0.0253 - val_acc: 0.9919\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 14s - loss: 0.0133 - acc: 0.9957 - val_loss: 0.0205 - val_acc: 0.9936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4f2a58f990>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model.fit_generator(batches, batches.n, nb_epoch=8, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning rate 0.01 -> 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsuyoshi/.pyenv/versions/anaconda3-4.3.0/envs/py2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_13 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "conv_model = get_conv_model(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator()\n",
    "batches = gen.flow(X_train, y_train, batch_size=64) # keras.preprocessing.image.NumpyArrayIterator\n",
    "test_batches = gen.flow(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 15s - loss: 0.4162 - acc: 0.8715 - val_loss: 0.1998 - val_acc: 0.9390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4f294d0290>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model.fit_generator(batches, batches.n, nb_epoch=1, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model.optimizer.lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 15s - loss: 0.2737 - acc: 0.9179 - val_loss: 0.1611 - val_acc: 0.9520\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 14s - loss: 0.2568 - acc: 0.9219 - val_loss: 0.1607 - val_acc: 0.9503\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 14s - loss: 0.2400 - acc: 0.9288 - val_loss: 0.1737 - val_acc: 0.9446\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 14s - loss: 0.2329 - acc: 0.9313 - val_loss: 0.1471 - val_acc: 0.9545\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 14s - loss: 0.2316 - acc: 0.9309 - val_loss: 0.1436 - val_acc: 0.9574\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 14s - loss: 0.2289 - acc: 0.9320 - val_loss: 0.1479 - val_acc: 0.9565\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 14s - loss: 0.2278 - acc: 0.9332 - val_loss: 0.1475 - val_acc: 0.9546\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 14s - loss: 0.2219 - acc: 0.9352 - val_loss: 0.1436 - val_acc: 0.9582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4f28bf5350>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model.fit_generator(batches, batches.n, nb_epoch=8, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With batch normalization, we can use higher learning rate.\n",
    "\n",
    "https://deepage.net/deep_learning/2016/10/26/batch_normalization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bn_model(lr=0.001):\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1,28,28)),\n",
    "        ZeroPadding2D((1, 1)),\n",
    "        Convolution2D(32, 3, 3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        ZeroPadding2D((1, 1)),\n",
    "        Convolution2D(64, 3, 3, activation='relu'),  \n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(lr=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning rate 0.001 -> 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsuyoshi/.pyenv/versions/anaconda3-4.3.0/envs/py2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_14 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "bn_model = get_bn_model(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_14 (Lambda)               (None, 1, 28, 28)     0           lambda_input_14[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_27 (ZeroPadding2D) (None, 1, 30, 30)     0           lambda_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_27 (Convolution2D) (None, 32, 28, 28)    320         zeropadding2d_27[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_20 (BatchNorm (None, 32, 28, 28)    128         convolution2d_27[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_27 (MaxPooling2D)   (None, 32, 14, 14)    0           batchnormalization_20[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_28 (ZeroPadding2D) (None, 32, 16, 16)    0           maxpooling2d_27[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_28 (Convolution2D) (None, 64, 14, 14)    18496       zeropadding2d_28[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_21 (BatchNorm (None, 64, 14, 14)    256         convolution2d_28[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_28 (MaxPooling2D)   (None, 64, 7, 7)      0           batchnormalization_21[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)             (None, 3136)          0           maxpooling2d_28[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_27 (Dense)                 (None, 512)           1606144     flatten_14[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_22 (BatchNorm (None, 512)           2048        dense_27[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)             (None, 512)           0           batchnormalization_22[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_28 (Dense)                 (None, 10)            5130        dropout_14[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1,632,522\n",
      "Trainable params: 1,631,306\n",
      "Non-trainable params: 1,216\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator()\n",
    "batches = gen.flow(X_train, y_train, batch_size=64) # keras.preprocessing.image.NumpyArrayIterator\n",
    "test_batches = gen.flow(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 16s - loss: 0.1123 - acc: 0.9661 - val_loss: 0.0557 - val_acc: 0.9810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4f273dd490>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit_generator(batches, batches.n, nb_epoch=1, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0511 - acc: 0.9841 - val_loss: 0.0433 - val_acc: 0.9863\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0388 - acc: 0.9876 - val_loss: 0.0339 - val_acc: 0.9876\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0313 - acc: 0.9900 - val_loss: 0.0482 - val_acc: 0.9845\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0291 - acc: 0.9907 - val_loss: 0.0309 - val_acc: 0.9904\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0231 - acc: 0.9922 - val_loss: 0.0269 - val_acc: 0.9917\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0195 - acc: 0.9938 - val_loss: 0.0335 - val_acc: 0.9897\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0193 - acc: 0.9935 - val_loss: 0.0275 - val_acc: 0.9913\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0158 - acc: 0.9948 - val_loss: 0.0369 - val_acc: 0.9889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4f267ddc90>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit_generator(batches, batches.n, nb_epoch=8, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning rate 0.01 -> 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsuyoshi/.pyenv/versions/anaconda3-4.3.0/envs/py2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_15 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 28, 28)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "bn_model = get_bn_model(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator()\n",
    "batches = gen.flow(X_train, y_train, batch_size=64) # keras.preprocessing.image.NumpyArrayIterator\n",
    "test_batches = gen.flow(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 16s - loss: 0.1534 - acc: 0.9553 - val_loss: 0.1456 - val_acc: 0.9672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4f24a47890>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit_generator(batches, batches.n, nb_epoch=1, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.optimizer.lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0759 - acc: 0.9780 - val_loss: 0.0708 - val_acc: 0.9806\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0652 - acc: 0.9814 - val_loss: 0.1439 - val_acc: 0.9658\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0600 - acc: 0.9836 - val_loss: 0.0886 - val_acc: 0.9807\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0629 - acc: 0.9830 - val_loss: 0.0491 - val_acc: 0.9878\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0509 - acc: 0.9859 - val_loss: 0.0432 - val_acc: 0.9900\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0514 - acc: 0.9869 - val_loss: 0.0599 - val_acc: 0.9868\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0500 - acc: 0.9878 - val_loss: 0.0482 - val_acc: 0.9904\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 16s - loss: 0.0507 - acc: 0.9886 - val_loss: 0.0567 - val_acc: 0.9877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4f23e44bd0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit_generator(batches, batches.n, nb_epoch=8, \n",
    "                    validation_data=test_batches, nb_val_samples=test_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| | loss | acc | val_loss | val_acc |\n",
    "|---|---|---|---|---|\n",
    "| lr=0.001 -> 0.0001  | 0.0133 | 0.9957 | 0.0205 | 0.9936 | \n",
    "| BN, lr=0.001 -> 0.0001 | 0.0158 | 0.9948 | 0.0369 | 0.9889 |\n",
    "| lr=0.01 -> 0.001 | 0.2219 | 0.9352 | 0.1436 | 0.9582 |\n",
    "| BN, lr=0.01 -> 0.001 | 0.0507 | 0.9886 | 0.0567 | 0.9877 |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
