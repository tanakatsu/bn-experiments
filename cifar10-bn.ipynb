{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10 CNN （without BN vs with BN）\n",
    "\n",
    "https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 950 (CNMeM is enabled with initial size: 90.0% of memory, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "data_augmentation = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data, shuffled and split between train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 3, 32, 32)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert class vectors to binary class matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(ZeroPadding2D((1, 1), input_shape=x_train.shape[1:]))\n",
    "model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "zeropadding2d_1 (ZeroPadding2D)  (None, 3, 34, 34)     0           zeropadding2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 32, 32, 32)    896         zeropadding2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 32, 16, 16)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 32, 16, 16)    0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_2 (ZeroPadding2D)  (None, 32, 18, 18)    0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 64, 16, 16)    18496       zeropadding2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 64, 14, 14)    36928       convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 64, 7, 7)      0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 64, 7, 7)      0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 3136)          0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 512)           1606144     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 512)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 10)            5130        dropout_3[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1,667,594\n",
      "Trainable params: 1,667,594\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initiate RMSprop optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's train the model using RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 29s - loss: 1.8843 - acc: 0.3118 - val_loss: 1.6013 - val_acc: 0.4354\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.5730 - acc: 0.4282 - val_loss: 1.3658 - val_acc: 0.5180\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.4439 - acc: 0.4827 - val_loss: 1.2788 - val_acc: 0.5511\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.3562 - acc: 0.5174 - val_loss: 1.1935 - val_acc: 0.5846\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.2848 - acc: 0.5395 - val_loss: 1.2872 - val_acc: 0.5381\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 29s - loss: 1.2311 - acc: 0.5622 - val_loss: 1.0828 - val_acc: 0.6176\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.1902 - acc: 0.5781 - val_loss: 1.0449 - val_acc: 0.6350\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.1485 - acc: 0.5948 - val_loss: 1.0116 - val_acc: 0.6422\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.1178 - acc: 0.6044 - val_loss: 0.9730 - val_acc: 0.6582\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.0927 - acc: 0.6154 - val_loss: 0.9304 - val_acc: 0.6722\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.0607 - acc: 0.6254 - val_loss: 0.9165 - val_acc: 0.6767\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.0410 - acc: 0.6327 - val_loss: 0.8844 - val_acc: 0.6899\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.0255 - acc: 0.6384 - val_loss: 0.9609 - val_acc: 0.6708\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.0123 - acc: 0.6437 - val_loss: 0.8805 - val_acc: 0.6939\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.9991 - acc: 0.6503 - val_loss: 0.8664 - val_acc: 0.6954\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.9882 - acc: 0.6534 - val_loss: 0.8597 - val_acc: 0.7054\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.9760 - acc: 0.6584 - val_loss: 0.8234 - val_acc: 0.7101\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.9683 - acc: 0.6619 - val_loss: 0.8313 - val_acc: 0.7164\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.9553 - acc: 0.6669 - val_loss: 0.8502 - val_acc: 0.7097\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.9500 - acc: 0.6689 - val_loss: 0.8431 - val_acc: 0.7042\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.9498 - acc: 0.6738 - val_loss: 0.8457 - val_acc: 0.7138\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.9475 - acc: 0.6729 - val_loss: 0.8607 - val_acc: 0.7019\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.9374 - acc: 0.6752 - val_loss: 0.8230 - val_acc: 0.7250\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.9366 - acc: 0.6774 - val_loss: 0.8857 - val_acc: 0.7166\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.9294 - acc: 0.6788 - val_loss: 0.7889 - val_acc: 0.7295\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.9180 - acc: 0.6840 - val_loss: 0.8014 - val_acc: 0.7316\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.9238 - acc: 0.6837 - val_loss: 0.7822 - val_acc: 0.7350\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.9228 - acc: 0.6817 - val_loss: 0.7836 - val_acc: 0.7326\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.9173 - acc: 0.6837 - val_loss: 0.7851 - val_acc: 0.7348\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.9143 - acc: 0.6848 - val_loss: 0.8232 - val_acc: 0.7191\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.9135 - acc: 0.6866 - val_loss: 0.7656 - val_acc: 0.7447\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.9069 - acc: 0.6902 - val_loss: 0.7624 - val_acc: 0.7444\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.9094 - acc: 0.6888 - val_loss: 0.7931 - val_acc: 0.7312\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.9070 - acc: 0.6886 - val_loss: 0.8112 - val_acc: 0.7230\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.8989 - acc: 0.6924 - val_loss: 0.8271 - val_acc: 0.7325\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.8989 - acc: 0.6929 - val_loss: 0.8804 - val_acc: 0.7085\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.8964 - acc: 0.6943 - val_loss: 0.8567 - val_acc: 0.7113\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.8987 - acc: 0.6948 - val_loss: 0.7954 - val_acc: 0.7440\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.8993 - acc: 0.6948 - val_loss: 0.8136 - val_acc: 0.7275\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.8951 - acc: 0.6945 - val_loss: 0.7936 - val_acc: 0.7393\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.8903 - acc: 0.6960 - val_loss: 0.8483 - val_acc: 0.7398\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.8923 - acc: 0.6962 - val_loss: 0.7630 - val_acc: 0.7428\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.8855 - acc: 0.7007 - val_loss: 0.7691 - val_acc: 0.7486\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.8855 - acc: 0.6986 - val_loss: 0.7608 - val_acc: 0.7545\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.8838 - acc: 0.7015 - val_loss: 0.7501 - val_acc: 0.7516\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.8888 - acc: 0.6984 - val_loss: 0.8005 - val_acc: 0.7439\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.8799 - acc: 0.7029 - val_loss: 0.7699 - val_acc: 0.7405\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.8929 - acc: 0.6992 - val_loss: 0.7548 - val_acc: 0.7527\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.8862 - acc: 0.7015 - val_loss: 0.7652 - val_acc: 0.7428\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 28s - loss: 0.8875 - acc: 0.7005 - val_loss: 0.8007 - val_acc: 0.7398\n"
     ]
    }
   ],
   "source": [
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=epochs, validation_data=(x_test, y_test), shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This wll do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False, # set input mean to 0 over the dataset\n",
    "        samplewise_center=False, # set each sample mean to 0\n",
    "        featurewise_std_normalization=False, # devide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False, # devide each input by its std\n",
    "        zca_whitening=False, # apply ZCA whitening\n",
    "        rotation_range=0, # randomly rorate iamges in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1, # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1, # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True, # randomly flip images\n",
    "        vertical_flip=False # randomly flip images\n",
    "    )\n",
    "    \n",
    "    #  Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and  principal components if ZCA whitening is applied)\n",
    "    datagen.fit(x_train)\n",
    "    \n",
    "    # Fit the model on the batches generated by datagen.flow()\n",
    "    batches = datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "    gen = ImageDataGenerator()\n",
    "    val_batches = gen.flow(x_test, y_test, batch_size=batch_size, shuffle=False)\n",
    "    model.fit_generator(batches, batches.n, nb_epoch=epochs,\n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9408/10000 [===========================>..] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.800688494301\n",
      "Test accuracy: 0.7398\n"
     ]
    }
   ],
   "source": [
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning rate 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.rmsprop(lr=0.001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(ZeroPadding2D((1, 1), input_shape=x_train.shape[1:]))\n",
    "model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.6096 - acc: 0.4193 - val_loss: 1.4371 - val_acc: 0.4931\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.2859 - acc: 0.5462 - val_loss: 1.2442 - val_acc: 0.5648\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.2084 - acc: 0.5805 - val_loss: 1.0591 - val_acc: 0.6504\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.1928 - acc: 0.5939 - val_loss: 1.0788 - val_acc: 0.6360\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.2036 - acc: 0.5968 - val_loss: 1.1009 - val_acc: 0.6301\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.2360 - acc: 0.5870 - val_loss: 1.1494 - val_acc: 0.6140\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.2668 - acc: 0.5809 - val_loss: 1.0821 - val_acc: 0.6256\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.3189 - acc: 0.5647 - val_loss: 1.2086 - val_acc: 0.6082\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.3498 - acc: 0.5556 - val_loss: 1.2037 - val_acc: 0.5927\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.4095 - acc: 0.5391 - val_loss: 1.1440 - val_acc: 0.6277\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.4667 - acc: 0.5199 - val_loss: 1.1728 - val_acc: 0.6068\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.4736 - acc: 0.5154 - val_loss: 1.3810 - val_acc: 0.5386\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.4888 - acc: 0.5047 - val_loss: 1.5465 - val_acc: 0.5236\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.4882 - acc: 0.5046 - val_loss: 2.1681 - val_acc: 0.4874\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.4961 - acc: 0.5033 - val_loss: 1.1902 - val_acc: 0.5984\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.4986 - acc: 0.4993 - val_loss: 1.5446 - val_acc: 0.4605\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.5177 - acc: 0.4975 - val_loss: 1.4555 - val_acc: 0.5567\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.5382 - acc: 0.4847 - val_loss: 1.4409 - val_acc: 0.4855\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.5629 - acc: 0.4783 - val_loss: 1.3728 - val_acc: 0.5151\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.5670 - acc: 0.4744 - val_loss: 1.5004 - val_acc: 0.5263\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.5775 - acc: 0.4716 - val_loss: 1.4568 - val_acc: 0.4858\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.5992 - acc: 0.4676 - val_loss: 1.5878 - val_acc: 0.4198\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.6024 - acc: 0.4658 - val_loss: 1.3761 - val_acc: 0.5259\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.6020 - acc: 0.4632 - val_loss: 1.6068 - val_acc: 0.4952\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.6135 - acc: 0.4604 - val_loss: 1.4295 - val_acc: 0.5085\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.6351 - acc: 0.4488 - val_loss: 1.2763 - val_acc: 0.5528\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.6654 - acc: 0.4372 - val_loss: 1.5230 - val_acc: 0.4636\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.6848 - acc: 0.4348 - val_loss: 1.3455 - val_acc: 0.5328\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.7000 - acc: 0.4270 - val_loss: 1.5455 - val_acc: 0.5077\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.6881 - acc: 0.4274 - val_loss: 1.3327 - val_acc: 0.5357\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.7250 - acc: 0.4158 - val_loss: 1.5227 - val_acc: 0.4798\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.7493 - acc: 0.4089 - val_loss: 1.5427 - val_acc: 0.4627\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.7603 - acc: 0.4011 - val_loss: 1.6870 - val_acc: 0.3720\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.8041 - acc: 0.3848 - val_loss: 1.5639 - val_acc: 0.4284\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.7962 - acc: 0.3875 - val_loss: 1.6987 - val_acc: 0.3649\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.7921 - acc: 0.3843 - val_loss: 2.6723 - val_acc: 0.4258\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.8389 - acc: 0.3713 - val_loss: 1.5764 - val_acc: 0.4310\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.8440 - acc: 0.3655 - val_loss: 2.0040 - val_acc: 0.3546\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.8528 - acc: 0.3577 - val_loss: 1.5927 - val_acc: 0.4052\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.8917 - acc: 0.3500 - val_loss: 1.6647 - val_acc: 0.3542\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.9363 - acc: 0.3287 - val_loss: 1.7456 - val_acc: 0.3379\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.9629 - acc: 0.3211 - val_loss: 1.7949 - val_acc: 0.3272\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.9924 - acc: 0.3077 - val_loss: 1.7016 - val_acc: 0.3592\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 28s - loss: 1.9746 - acc: 0.3062 - val_loss: 2.1767 - val_acc: 0.1808\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 28s - loss: 2.0067 - acc: 0.2929 - val_loss: 1.7170 - val_acc: 0.3300\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 28s - loss: 2.0115 - acc: 0.2852 - val_loss: 1.8963 - val_acc: 0.2658\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 28s - loss: 2.0726 - acc: 0.2633 - val_loss: 1.9656 - val_acc: 0.2500\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 28s - loss: 2.1103 - acc: 0.2425 - val_loss: 1.8225 - val_acc: 0.3171\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 28s - loss: 2.1527 - acc: 0.2381 - val_loss: 1.9862 - val_acc: 0.2133\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 28s - loss: 2.1267 - acc: 0.2226 - val_loss: 2.0676 - val_acc: 0.2230\n"
     ]
    }
   ],
   "source": [
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=epochs, validation_data=(x_test, y_test), shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This wll do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False, # set input mean to 0 over the dataset\n",
    "        samplewise_center=False, # set each sample mean to 0\n",
    "        featurewise_std_normalization=False, # devide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False, # devide each input by its std\n",
    "        zca_whitening=False, # apply ZCA whitening\n",
    "        rotation_range=0, # randomly rorate iamges in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1, # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1, # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True, # randomly flip images\n",
    "        vertical_flip=False # randomly flip images\n",
    "    )\n",
    "    \n",
    "    #  Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and  principal components if ZCA whitening is applied)\n",
    "    datagen.fit(x_train)\n",
    "    \n",
    "    # Fit the model on the batches generated by datagen.flow()\n",
    "    batches = datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "    gen = ImageDataGenerator()\n",
    "    val_batches = gen.flow(x_test, y_test, batch_size=batch_size, shuffle=False)\n",
    "    model.fit_generator(batches, batches.n, nb_epoch=epochs,\n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.add(ZeroPadding2D((1, 1), input_shape=x_train.shape[1:]))\n",
    "bn_model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "bn_model.add(BatchNormalization(axis=1)),\n",
    "bn_model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "bn_model.add(Dropout(0.25))\n",
    "bn_model.add(ZeroPadding2D((1, 1)))\n",
    "bn_model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "bn_model.add(BatchNormalization(axis=1)),\n",
    "bn_model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "bn_model.add(BatchNormalization(axis=1)),\n",
    "bn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "bn_model.add(Dropout(0.25))\n",
    "bn_model.add(Flatten())\n",
    "bn_model.add(Dense(512, activation='relu'))\n",
    "bn_model.add(BatchNormalization())\n",
    "bn_model.add(Dropout(0.5))\n",
    "bn_model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "zeropadding2d_5 (ZeroPadding2D)  (None, 3, 34, 34)     0           zeropadding2d_input_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 32, 32, 32)    896         zeropadding2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 32, 32, 32)    128         convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 32, 16, 16)    0           batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 32, 16, 16)    0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_6 (ZeroPadding2D)  (None, 32, 18, 18)    0           dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 64, 16, 16)    18496       zeropadding2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 64, 16, 16)    256         convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 64, 14, 14)    36928       batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 64, 14, 14)    256         convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 64, 7, 7)      0           batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 64, 7, 7)      0           maxpooling2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 3136)          0           dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 512)           1606144     flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_4 (BatchNorma (None, 512)           2048        dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 512)           0           batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 10)            5130        dropout_9[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1,670,282\n",
      "Trainable params: 1,668,938\n",
      "Non-trainable params: 1,344\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 31s - loss: 2.1880 - acc: 0.3482 - val_loss: 1.5356 - val_acc: 0.4571\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 31s - loss: 1.6650 - acc: 0.4537 - val_loss: 1.3970 - val_acc: 0.5078\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 31s - loss: 1.4475 - acc: 0.5098 - val_loss: 1.1492 - val_acc: 0.5997\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 31s - loss: 1.3001 - acc: 0.5524 - val_loss: 1.1796 - val_acc: 0.5838\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 31s - loss: 1.2068 - acc: 0.5813 - val_loss: 1.1365 - val_acc: 0.5999\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 31s - loss: 1.1366 - acc: 0.6006 - val_loss: 1.1153 - val_acc: 0.6061\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 31s - loss: 1.0767 - acc: 0.6227 - val_loss: 1.0457 - val_acc: 0.6280\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 31s - loss: 1.0298 - acc: 0.6395 - val_loss: 1.1614 - val_acc: 0.5957\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.9965 - acc: 0.6518 - val_loss: 0.9503 - val_acc: 0.6619\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.9648 - acc: 0.6643 - val_loss: 0.8599 - val_acc: 0.6938\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.9400 - acc: 0.6687 - val_loss: 0.9148 - val_acc: 0.6830\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.9148 - acc: 0.6813 - val_loss: 0.8451 - val_acc: 0.7060\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.8912 - acc: 0.6895 - val_loss: 0.8833 - val_acc: 0.6972\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.8751 - acc: 0.6953 - val_loss: 0.8433 - val_acc: 0.7088\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.8563 - acc: 0.7039 - val_loss: 1.1780 - val_acc: 0.6038\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.8409 - acc: 0.7070 - val_loss: 0.8864 - val_acc: 0.6912\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.8355 - acc: 0.7103 - val_loss: 0.8703 - val_acc: 0.6999\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.8179 - acc: 0.7162 - val_loss: 0.8502 - val_acc: 0.7047\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.8103 - acc: 0.7209 - val_loss: 0.7309 - val_acc: 0.7405\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.7918 - acc: 0.7258 - val_loss: 0.7560 - val_acc: 0.7404\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.7860 - acc: 0.7268 - val_loss: 0.7750 - val_acc: 0.7303\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.7753 - acc: 0.7307 - val_loss: 0.7920 - val_acc: 0.7292\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.7696 - acc: 0.7339 - val_loss: 0.7207 - val_acc: 0.7519\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.7569 - acc: 0.7368 - val_loss: 0.7612 - val_acc: 0.7380\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.7536 - acc: 0.7367 - val_loss: 0.7808 - val_acc: 0.7330\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.7397 - acc: 0.7455 - val_loss: 0.7955 - val_acc: 0.7339\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.7433 - acc: 0.7422 - val_loss: 0.7533 - val_acc: 0.7392\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.7310 - acc: 0.7484 - val_loss: 0.7221 - val_acc: 0.7520\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.7310 - acc: 0.7490 - val_loss: 0.6867 - val_acc: 0.7676\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.7215 - acc: 0.7522 - val_loss: 0.6884 - val_acc: 0.7664\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.7172 - acc: 0.7536 - val_loss: 0.7345 - val_acc: 0.7506\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.7109 - acc: 0.7547 - val_loss: 0.6761 - val_acc: 0.7701\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.7076 - acc: 0.7559 - val_loss: 0.6536 - val_acc: 0.7779\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6997 - acc: 0.7603 - val_loss: 0.7198 - val_acc: 0.7533\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6981 - acc: 0.7594 - val_loss: 0.7618 - val_acc: 0.7418\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6920 - acc: 0.7627 - val_loss: 0.7611 - val_acc: 0.7459\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6839 - acc: 0.7641 - val_loss: 0.6407 - val_acc: 0.7780\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6892 - acc: 0.7637 - val_loss: 0.8634 - val_acc: 0.7180\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6796 - acc: 0.7666 - val_loss: 0.7612 - val_acc: 0.7440\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6698 - acc: 0.7696 - val_loss: 0.7118 - val_acc: 0.7601\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6717 - acc: 0.7697 - val_loss: 0.7919 - val_acc: 0.7391\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6669 - acc: 0.7715 - val_loss: 0.6747 - val_acc: 0.7731\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6726 - acc: 0.7696 - val_loss: 0.6106 - val_acc: 0.7939\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6645 - acc: 0.7714 - val_loss: 0.6564 - val_acc: 0.7778\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6661 - acc: 0.7703 - val_loss: 0.6912 - val_acc: 0.7656\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6598 - acc: 0.7741 - val_loss: 0.7371 - val_acc: 0.7567\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6539 - acc: 0.7765 - val_loss: 0.6778 - val_acc: 0.7773\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6506 - acc: 0.7777 - val_loss: 0.8968 - val_acc: 0.7133\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6480 - acc: 0.7776 - val_loss: 0.7375 - val_acc: 0.7553\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6417 - acc: 0.7824 - val_loss: 0.7124 - val_acc: 0.7671\n"
     ]
    }
   ],
   "source": [
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    bn_model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=epochs, validation_data=(x_test, y_test), shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This wll do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False, # set input mean to 0 over the dataset\n",
    "        samplewise_center=False, # set each sample mean to 0\n",
    "        featurewise_std_normalization=False, # devide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False, # devide each input by its std\n",
    "        zca_whitening=False, # apply ZCA whitening\n",
    "        rotation_range=0, # randomly rorate iamges in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1, # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1, # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True, # randomly flip images\n",
    "        vertical_flip=False # randomly flip images\n",
    "    )\n",
    "    \n",
    "    #  Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and  principal components if ZCA whitening is applied)\n",
    "    datagen.fit(x_train)\n",
    "    \n",
    "    # Fit the model on the batches generated by datagen.flow()\n",
    "    batches = datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "    gen = ImageDataGenerator()\n",
    "    val_batches = gen.flow(x_test, y_test, batch_size=batch_size, shuffle=False)\n",
    "    bn_model.fit_generator(batches, batches.n, nb_epoch=epochs,\n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9632/10000 [===========================>..] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "scores = bn_model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.712403135777\n",
      "Test accuracy: 0.7671\n"
     ]
    }
   ],
   "source": [
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning rate 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.rmsprop(lr=0.001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.add(ZeroPadding2D((1, 1), input_shape=x_train.shape[1:]))\n",
    "bn_model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "bn_model.add(BatchNormalization(axis=1)),\n",
    "bn_model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "bn_model.add(Dropout(0.25))\n",
    "bn_model.add(ZeroPadding2D((1, 1)))\n",
    "bn_model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "bn_model.add(BatchNormalization(axis=1)),\n",
    "bn_model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "bn_model.add(BatchNormalization(axis=1)),\n",
    "bn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "bn_model.add(Dropout(0.25))\n",
    "bn_model.add(Flatten())\n",
    "bn_model.add(Dense(512, activation='relu'))\n",
    "bn_model.add(BatchNormalization())\n",
    "bn_model.add(Dropout(0.5))\n",
    "bn_model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 31s - loss: 1.6300 - acc: 0.4533 - val_loss: 1.4874 - val_acc: 0.4848\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 31s - loss: 1.1827 - acc: 0.5836 - val_loss: 1.0517 - val_acc: 0.6315\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 31s - loss: 1.0635 - acc: 0.6270 - val_loss: 0.9839 - val_acc: 0.6462\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.9956 - acc: 0.6538 - val_loss: 1.0255 - val_acc: 0.6427\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.9457 - acc: 0.6710 - val_loss: 1.3417 - val_acc: 0.5681\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.9064 - acc: 0.6864 - val_loss: 1.6020 - val_acc: 0.5165\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.8712 - acc: 0.6986 - val_loss: 0.8437 - val_acc: 0.7122\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.8422 - acc: 0.7066 - val_loss: 0.7225 - val_acc: 0.7546\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.8255 - acc: 0.7171 - val_loss: 0.8167 - val_acc: 0.7196\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.8132 - acc: 0.7188 - val_loss: 0.9594 - val_acc: 0.6754\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.7856 - acc: 0.7330 - val_loss: 0.7113 - val_acc: 0.7525\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.7724 - acc: 0.7340 - val_loss: 0.7866 - val_acc: 0.7304\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.7662 - acc: 0.7381 - val_loss: 0.7972 - val_acc: 0.7291\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.7485 - acc: 0.7459 - val_loss: 0.6980 - val_acc: 0.7581\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.7398 - acc: 0.7455 - val_loss: 0.7062 - val_acc: 0.7651\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.7311 - acc: 0.7511 - val_loss: 0.6995 - val_acc: 0.7590\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.7154 - acc: 0.7572 - val_loss: 0.6745 - val_acc: 0.7821\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.7125 - acc: 0.7591 - val_loss: 0.6322 - val_acc: 0.7855\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.7056 - acc: 0.7612 - val_loss: 0.5946 - val_acc: 0.8006\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6980 - acc: 0.7662 - val_loss: 0.6019 - val_acc: 0.7979\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6856 - acc: 0.7683 - val_loss: 0.5812 - val_acc: 0.8074\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6834 - acc: 0.7698 - val_loss: 0.6088 - val_acc: 0.7921\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6775 - acc: 0.7699 - val_loss: 0.6046 - val_acc: 0.7985\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6720 - acc: 0.7707 - val_loss: 0.7368 - val_acc: 0.7587\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6695 - acc: 0.7730 - val_loss: 0.6273 - val_acc: 0.7936\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6683 - acc: 0.7766 - val_loss: 0.7079 - val_acc: 0.7683\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6621 - acc: 0.7768 - val_loss: 0.7094 - val_acc: 0.7700\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6530 - acc: 0.7776 - val_loss: 0.6364 - val_acc: 0.7844\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6484 - acc: 0.7817 - val_loss: 0.5981 - val_acc: 0.7972\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6467 - acc: 0.7810 - val_loss: 0.6719 - val_acc: 0.7710\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6417 - acc: 0.7825 - val_loss: 0.7739 - val_acc: 0.7617\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6392 - acc: 0.7818 - val_loss: 0.5877 - val_acc: 0.8053\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6352 - acc: 0.7863 - val_loss: 0.6429 - val_acc: 0.7948\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6352 - acc: 0.7869 - val_loss: 0.6152 - val_acc: 0.7983\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6282 - acc: 0.7902 - val_loss: 0.5305 - val_acc: 0.8204\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6291 - acc: 0.7873 - val_loss: 1.0295 - val_acc: 0.7003\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6233 - acc: 0.7892 - val_loss: 0.5817 - val_acc: 0.8024\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6222 - acc: 0.7907 - val_loss: 0.5163 - val_acc: 0.8303\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6208 - acc: 0.7905 - val_loss: 0.5549 - val_acc: 0.8124\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6136 - acc: 0.7935 - val_loss: 0.7084 - val_acc: 0.7753\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6091 - acc: 0.7963 - val_loss: 0.5147 - val_acc: 0.8264\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6122 - acc: 0.7951 - val_loss: 0.5643 - val_acc: 0.8096\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6071 - acc: 0.7959 - val_loss: 0.6333 - val_acc: 0.7882\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6014 - acc: 0.7981 - val_loss: 0.5500 - val_acc: 0.8174\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6048 - acc: 0.7959 - val_loss: 0.6581 - val_acc: 0.7886\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.5988 - acc: 0.7996 - val_loss: 0.5395 - val_acc: 0.8168\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.6063 - acc: 0.7953 - val_loss: 0.4973 - val_acc: 0.8286\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.5939 - acc: 0.8001 - val_loss: 0.5939 - val_acc: 0.8055\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.5947 - acc: 0.7991 - val_loss: 0.7210 - val_acc: 0.7800\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 31s - loss: 0.5938 - acc: 0.8006 - val_loss: 0.5055 - val_acc: 0.8264\n"
     ]
    }
   ],
   "source": [
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    bn_model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=epochs, validation_data=(x_test, y_test), shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This wll do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False, # set input mean to 0 over the dataset\n",
    "        samplewise_center=False, # set each sample mean to 0\n",
    "        featurewise_std_normalization=False, # devide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False, # devide each input by its std\n",
    "        zca_whitening=False, # apply ZCA whitening\n",
    "        rotation_range=0, # randomly rorate iamges in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1, # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1, # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True, # randomly flip images\n",
    "        vertical_flip=False # randomly flip images\n",
    "    )\n",
    "    \n",
    "    #  Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and  principal components if ZCA whitening is applied)\n",
    "    datagen.fit(x_train)\n",
    "    \n",
    "    # Fit the model on the batches generated by datagen.flow()\n",
    "    batches = datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "    gen = ImageDataGenerator()\n",
    "    val_batches = gen.flow(x_test, y_test, batch_size=batch_size, shuffle=False)\n",
    "    bn_model.fit_generator(batches, batches.n, nb_epoch=epochs,\n",
    "                        validation_data=val_batches, nb_val_samples=val_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| | loss | acc | val_loss | val_acc |\n",
    "|---|---|---|---|---|\n",
    "| lr=0.0001 | 0.8875 | 0.7005 | 0.8007 | 0.7398 | \n",
    "| BN, lr=0.0001 | 0.6417 | 0.7824 | 0.7124 | 0.7671 |\n",
    "| lr=0.001 | 2.1267 | 0.2226 | 2.0676 | 0.2230 |\n",
    "| BN, lr=0.001 | 0.5938 | 0.8006 | 0.5055 | 0.8264 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
